{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Tim's scoring output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Lipinski import RotatableBondSmarts\n",
    "from rdkit.Chem import BRICS\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.FeatMaps import FeatMaps\n",
    "from rdkit.Chem import AllChem, rdShapeHelpers\n",
    "from rdkit import RDConfig\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "def getBits(mol):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mol : rdkit mol object to be broken up into fragments by breaking \n",
    "    rotable bonds\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mols : A list of rdkit mol objects\n",
    "\n",
    "    '''\n",
    "    # find the rotatable bonds\n",
    "    bonds = mol.GetSubstructMatches(RotatableBondSmarts)\n",
    "    \n",
    "    bonds = [((x,y),(0,0)) for x,y in bonds]\n",
    "    p = BRICS.BreakBRICSBonds(mol,bonds=bonds)\n",
    " \n",
    "    mols = [mol for mol in Chem.GetMolFrags(p,asMols=True)]\n",
    "    \n",
    "    return mols\n",
    "\n",
    "# Function to build feature maps and score two mol objects\n",
    "fdef = AllChem.BuildFeatureFactory(os.path.join(RDConfig.RDDataDir, 'BaseFeatures.fdef'))\n",
    "\n",
    "fmParams = {}\n",
    "for k in fdef.GetFeatureFamilies():\n",
    "    fparams = FeatMaps.FeatMapParams()\n",
    "    fmParams[k] = fparams\n",
    "\n",
    "keep = ('Donor', 'Acceptor', 'NegIonizable', 'PosIonizable', 'ZnBinder',\n",
    "        'Aromatic', 'Hydrophobe', 'LumpedHydrophobe')\n",
    "\n",
    "def getFeatureMapScore(small_m, large_m, score_mode=FeatMaps.FeatMapScoreMode.All):\n",
    "    try: \n",
    "        featLists = []\n",
    "        for m in [small_m, large_m]:\n",
    "            rawFeats = fdef.GetFeaturesForMol(m)\n",
    "            # filter that list down to only include the ones we're intereted in\n",
    "            featLists.append([f for f in rawFeats if f.GetFamily() in keep])\n",
    "        fms = [FeatMaps.FeatMap(feats=x, weights=[1] * len(x), params=fmParams) for x in featLists]\n",
    "        fms[0].scoreMode = score_mode\n",
    "        fm_score = fms[0].ScoreFeats(featLists[1]) / min(fms[0].GetNumFeatures(), len(featLists[1]))\n",
    "        return fm_score\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def getNumberfeats(mol):\n",
    "    \n",
    "    featLists = []\n",
    "    rawFeats = fdef.GetFeaturesForMol(mol)\n",
    "    # filter that list down to only include the ones we're intereted in\n",
    "    featLists.append([f for f in rawFeats if f.GetFamily() in keep])\n",
    "    \n",
    "    return len(featLists)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# We need to start by building a FeatureFactory object which defines \n",
    "# the set of pharmacophore features being used. \n",
    "# We'll use this to find features on the molecules.\n",
    "fdef = AllChem.BuildFeatureFactory(os.path.join(RDConfig.RDDataDir, \n",
    "                                                'BaseFeatures.fdef'))\n",
    "\n",
    "\n",
    "# Set default paramters for selecting points in feature map\n",
    "fmParams = {}\n",
    "for k in fdef.GetFeatureFamilies():\n",
    "    fparams = FeatMaps.FeatMapParams()\n",
    "    fmParams[k] = fparams\n",
    "\n",
    "# List of feature families that we want to use\n",
    "keep = ('Donor', 'Acceptor', 'NegIonizable', 'PosIonizable', 'ZnBinder',\n",
    "        'Aromatic', 'Hydrophobe', 'LumpedHydrophobe')\n",
    "\n",
    "\n",
    "def getFeatureMap(mol_list):\n",
    "    allFeats = []\n",
    "    for m in mol_list:\n",
    "        \n",
    "        rawFeats = fdef.GetFeaturesForMol(m)\n",
    "        featDeats = [(f.GetType(),\n",
    "                      f.GetPos().x,\n",
    "                      f.GetPos().y,\n",
    "                      f.GetPos().z) for f in rawFeats if f.GetFamily() in keep]\n",
    "        \n",
    "        allFeats.append(featDeats)\n",
    "        \n",
    "\n",
    "    feature_map_df = pd.DataFrame([t for lst in allFeats for t in lst],\n",
    "                                  columns =['featType', 'x', 'y', 'z']) \n",
    "   \n",
    "    return feature_map_df\n",
    "\n",
    "\n",
    "def getFeatureAgg(feature_map_df, rad_thresh):\n",
    "    \n",
    "    # Group data into unique feature types\n",
    "    grouped_df = feature_map_df.groupby('featType')\n",
    "    \n",
    "    data_to_add = []\n",
    "    \n",
    "    for group_name, df_group in grouped_df:\n",
    "        \n",
    "        # Reset index df\n",
    "        df_group = df_group.reset_index()\n",
    "\n",
    "        if len(df_group) == 1:\n",
    "            \n",
    "            data_to_add.append(df_group)\n",
    "        \n",
    "        if len(df_group) > 1:\n",
    "                \n",
    "            # Get feature name\n",
    "            feat_name = df_group.featType.unique()[0]\n",
    "\n",
    "            # Use radius neighbours to find features within \n",
    "            # spere with radius thresh\n",
    "            neigh = NearestNeighbors(radius=rad_thresh)\n",
    "            \n",
    "            while len(df_group) > 0:\n",
    "                \n",
    "                neigh.fit(df_group[['x','y','z']])\n",
    "            \n",
    "                # Get distances and indices of neigbours within radius threshold\n",
    "                rng = neigh.radius_neighbors()\n",
    "                neigh_dist = rng[0][0]\n",
    "                neigh_indices = rng[1][0]\n",
    "                \n",
    "                # Append the first index - NB clustering done relative to index 0\n",
    "                neigh_indices = list(np.append(0, neigh_indices))\n",
    "                \n",
    "                # Calculate average x,y,z coords for features in similar loc\n",
    "                x_avg = np.mean(df_group.iloc[neigh_indices].x)\n",
    "                y_avg = np.mean(df_group.iloc[neigh_indices].y)\n",
    "                z_avg = np.mean(df_group.iloc[neigh_indices].z)\n",
    "                \n",
    "                # Add feature with average x, y and z values\n",
    "                new_row = [(feat_name, x_avg, y_avg, z_avg)]\n",
    "                \n",
    "                cluster_df = pd.DataFrame(data=new_row, columns = ['featType', 'x', 'y', 'z'])\n",
    "                \n",
    "                data_to_add.append(cluster_df)\n",
    "                \n",
    "                # Remove indices of clustered neigbours\n",
    "                df_group = df_group.drop(df_group.index[neigh_indices])\n",
    "        \n",
    "    # Create single DF from list of dfs\n",
    "    clustered_df = pd.concat(data_to_add)\n",
    "\n",
    "    return clustered_df\n",
    "\n",
    "\n",
    "def getSDFprops(compound_mol):\n",
    "    # Need to change for diff sdf files!!!\n",
    "    \n",
    "    # Make smiles = original SMILES \n",
    "    compound_mol.SetProp('original SMILES', compound_mol.GetProp('OrigSmiles'))\n",
    "    \n",
    "    # Assign ref pdb\n",
    "    compound_mol.SetProp('ref_pdb', 'Fragmenstein.pdb')\n",
    "    \n",
    "    # Get all the sdf properties\n",
    "    all_properties = list(compound_mol.GetPropsAsDict().keys())\n",
    "\n",
    "    # Properties to keep \n",
    "    keep_properties = ['ref_pdb', 'ref_mols', 'original SMILES', \n",
    "                       'XCos_RefMols', 'XCos_NumHits', \n",
    "                       'XCos_Score1', 'XCos_Score2', 'XCos_Score3'] \n",
    "\n",
    "    # Properties to delete\n",
    "    del_properties = [prop for prop in all_properties if prop not in keep_properties]\n",
    "\n",
    "    for prop in del_properties:\n",
    "            compound_mol.ClearProp(prop)\n",
    "\n",
    "    return compound_mol\n",
    "\n",
    "\n",
    "def getBlankMol(blank_mol, COS_threshold, rad_threshold):\n",
    "    \n",
    "    # Add compulsory props\n",
    "    blank_mol.SetProp('_Name', 'ver_1.2')\n",
    "    blank_mol.SetProp('ref_mols', 'Fragments that bits overlap with above a score threshold of {}.'.format(COS_threshold))\n",
    "    blank_mol.SetProp('ref_url', 'https://github.com/Waztom/xchem-xCOS')\n",
    "    blank_mol.SetProp('submitter_name', 'WT')\n",
    "    blank_mol.SetProp('submitter_email', 'warren.thompson@diamond.ac.uk')\n",
    "    blank_mol.SetProp('submitter_institution', 'Diamond Light Source')\n",
    "    blank_mol.SetProp('generation_date', date)\n",
    "    blank_mol.SetProp('method', 'xCOS')\n",
    "\n",
    "    # Add scoring descriptors\n",
    "    blank_mol.SetProp('N_hits', 'The number of fragments that bits overlap with above a score threshold of {}.'.format(COS_threshold))\n",
    "    blank_mol.SetProp('Score_1', 'The score is scaled by the number of bit atoms')    \n",
    "    blank_mol.SetProp('Score_2', 'The score is scaled by the number of bit atoms penalised by the fraction of feats matched the to total number feats clustered within a {} angstrom threshold'.format(rad_threshold))    \n",
    "    blank_mol.SetProp('Score_3', 'The score is determined by the fraction of matching features to the clustered features within a {} angstrom threshold.'.format(rad_threshold))\n",
    "    return blank_mol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in fragment mols\n",
    "frag_mol_list = Chem.SDMolSupplier('in_data/check_xcos/hits-69.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tim's XCOS data to compare with\n",
    "compound_mols = Chem.SDMolSupplier('in_data/check_xcos/scored_part_0005.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 clustered features found with radius threshold 1.5\n"
     ]
    }
   ],
   "source": [
    "# Get the feature map df with coordinates and feature info\n",
    "feature_map_df =  getFeatureMap(frag_mol_list)\n",
    "\n",
    "# Set radius threshold \n",
    "rad_thresh = 1.5\n",
    "\n",
    "# Aggregate features using nearest neigbours algo\n",
    "clustered_df = getFeatureAgg(feature_map_df,\n",
    "                             rad_thresh=rad_thresh)\n",
    "\n",
    "# Get number of clustered feats\n",
    "no_clustered_feats = len(clustered_df)\n",
    "print('{} clustered features found with radius threshold {}'.format(no_clustered_feats, rad_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReverseScores(clustered_df, compound_mols, rad_threshold, \n",
    "                     COS_threshold, filename):\n",
    "    \n",
    "    # Get writer set up for writing final mols to file\n",
    "    w = Chem.SDWriter(filename)\n",
    "       \n",
    "    # Score eveything besides for first mol\n",
    "    for i in range(len(compound_mols)):\n",
    "\n",
    "        # Get compound mol\n",
    "        compound_mol = compound_mols[i]\n",
    "\n",
    "        # Get the bits\n",
    "        compound_bits = getBits(compound_mol)\n",
    "\n",
    "        # We are going to include a feature mapping score, where the \n",
    "        # number of features of the compound matching the clustered feats \n",
    "        # within a threshold are found\n",
    "\n",
    "        # Get feature map of compound bits as df\n",
    "        feature_map_bits = getFeatureMap(compound_bits)\n",
    "\n",
    "        # Group data into unique feature types\n",
    "        grouped_df = feature_map_bits.groupby('featType')\n",
    "\n",
    "        no_feats_matched = []\n",
    "        dist_feats_matched = []\n",
    "\n",
    "        # Use radius neighbours to find features within \n",
    "        # sphere with radius thresh\n",
    "        neigh = NearestNeighbors(radius=rad_threshold)\n",
    "\n",
    "        # Loop through grouped features\n",
    "        for group_name, df_group in grouped_df:          \n",
    "\n",
    "            # Get feat name\n",
    "            feat_name = df_group.featType.unique()[0]\n",
    "\n",
    "            # Get simmilar feats from cluster df\n",
    "            cluster_test = clustered_df[clustered_df.featType==feat_name]\n",
    "\n",
    "            # Reset index df\n",
    "            df_group = df_group.reset_index()\n",
    "\n",
    "            if len(cluster_test) == 1:\n",
    "\n",
    "                # Calculate distances\n",
    "                x1_sub_x2 = (cluster_test.iloc[0].x - df_group.iloc[0].x)**2\n",
    "                y1_sub_y2 = (cluster_test.iloc[0].y - df_group.iloc[0].y)**2\n",
    "                z1_sub_z2 = (cluster_test.iloc[0].z - df_group.iloc[0].z)**2\n",
    "\n",
    "                diff_sum = x1_sub_x2 + y1_sub_y2 + z1_sub_z2\n",
    "\n",
    "                dist = diff_sum**0.5\n",
    "\n",
    "                if dist < rad_threshold:\n",
    "\n",
    "                    # Let's get the number of feats matched\n",
    "                    no_feats_matched.append(1)\n",
    "\n",
    "                    # Let's get the distance of the feats matched\n",
    "                    dist_feats_matched.append([dist])                \n",
    "\n",
    "            if len(cluster_test) > 1:\n",
    "                neigh.fit(cluster_test[['x','y','z']])\n",
    "\n",
    "                while len(df_group) > 0:\n",
    "\n",
    "                    # Get distances and indices of neigbours within radius threshold\n",
    "                    feat_coords = [[df_group.iloc[0].x, df_group.iloc[0].y, df_group.iloc[0].z]]\n",
    "                    rng = neigh.radius_neighbors(feat_coords)\n",
    "\n",
    "                    neigh_dist = rng[0][0]\n",
    "                    neigh_indices = rng[1][0]\n",
    "\n",
    "                    # Let's get the number of feats matched\n",
    "                    no_feats_matched.append(len(neigh_indices))\n",
    "\n",
    "                    # Remove index 0 of df_group\n",
    "                    df_group = df_group.drop(df_group.index[0])\n",
    "\n",
    "        # Get total number of feat matches \n",
    "        no_feats = np.sum(no_feats_matched)\n",
    "\n",
    "        all_scores = []\n",
    "\n",
    "        for bit in compound_bits:\n",
    "\n",
    "            # Get number of bit atoms\n",
    "            no_bit_atoms = bit.GetNumAtoms()\n",
    "\n",
    "            scores = []\n",
    "            for frag_mol in frag_mol_list:\n",
    "\n",
    "                    # NB reverse SuCOS scoring\n",
    "                    fm_score = getFeatureMapScore(bit, frag_mol)\n",
    "                    fm_score = np.clip(fm_score, 0, 1)             \n",
    "                    protrude_dist = rdShapeHelpers.ShapeProtrudeDist(bit, frag_mol,\n",
    "                                                                     allowReordering=False)\n",
    "                    protrude_dist = np.clip(protrude_dist, 0, 1)\n",
    "\n",
    "                    reverse_SuCOS_score = 0.5*fm_score + 0.5*(1 - protrude_dist)\n",
    "\n",
    "                    # Get number of feats from bit for scaling score\n",
    "                    no_bit_feats = getNumberfeats(bit)\n",
    "\n",
    "                    # Get some info and append to list\n",
    "                    frag_name = frag_mol.GetProp('_Name').strip('Mpro-')\n",
    "\n",
    "                    scores.append((frag_name, reverse_SuCOS_score, no_bit_atoms, no_bit_feats))\n",
    "\n",
    "            all_scores.append(scores)\n",
    "\n",
    "            list_dfs = [] \n",
    "            for score in all_scores:\n",
    "                df = pd.DataFrame(data=score, columns = ['Fragment','Score','No_bit_atoms', 'No_bit_feats'])\n",
    "                # Get maximum scoring fragment for bit match\n",
    "                df = df[df['Score'] == df['Score'].max()]\n",
    "                list_dfs.append(df)\n",
    "\n",
    "            final_df = pd.concat(list_dfs)\n",
    "\n",
    "            # Get total bit score and some denominator terms\n",
    "            bits_score = (final_df.No_bit_atoms * final_df.Score).sum()\n",
    "            total_atoms = final_df.No_bit_atoms.sum()\n",
    "            feat_match_fraction = no_feats / no_clustered_feats\n",
    "\n",
    "            # Score 1: the score is scaled by the number of bit atoms\n",
    "            score_1 = bits_score\n",
    "\n",
    "            # Score 2: the score is scaled by the number of bit atoms\n",
    "            # penalised by the fraction of feats matched \n",
    "            # the to total number feats clustered\n",
    "            score_2 = score_1 * feat_match_fraction\n",
    "\n",
    "            # Score 3: the score is determined by the fraction of matching \n",
    "            # features to the clustered features within a threshold. This\n",
    "            # should yield similar values to Tim's Featurestein method?\n",
    "            score_3 = feat_match_fraction\n",
    "\n",
    "            # Let's only get frags above a threshold\n",
    "            final_df = final_df[final_df.Score > COS_threshold]\n",
    "\n",
    "            # Let#s sort the df by increasing score\n",
    "            final_df = final_df.sort_values(by=['Score'], ascending=False)\n",
    "\n",
    "            # Get the unique fragments above threshold\n",
    "            all_frags = pd.unique(final_df.Fragment)\n",
    "\n",
    "        # Set sdf props - see function for props to keep and drop            \n",
    "        compound_mol = getSDFprops(compound_mol)\n",
    "\n",
    "        # Add props we want                                   \n",
    "        compound_mol.SetProp('ref_mols',','.join(all_frags))\n",
    "        compound_mol.SetProp('N_hits', str(len(all_frags)))\n",
    "        compound_mol.SetProp('Score_1', \"{:.4f}\".format(score_1))\n",
    "        compound_mol.SetProp('Score_2', \"{:.4f}\".format(score_2))\n",
    "        compound_mol.SetProp('Score_3', \"{:.4f}\".format(score_3))\n",
    "\n",
    "\n",
    "        # Write to file\n",
    "        w.write(compound_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do all of the compounds\n",
    "getReverseScores(clustered_df=clustered_df, compound_mols=compound_mols,\n",
    "                 rad_threshold=1.0, COS_threshold=0.50, \n",
    "                 filename='out_data/xCOS_check_{}.sdf'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
